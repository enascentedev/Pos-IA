{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Semana 7 — Aprendizado Supervisionado\n\nNotebook com comparação de modelos clássicos de classificação, validação cruzada, ensemble com Gradient Boosting e análise de métricas (accuracy, F1, AUC)."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, roc_curve, auc, precision_recall_curve, average_precision_score\n\nplt.style.use('seaborn-v0_8')\nnp.random.seed(42)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Carregamento e divisão do dataset\n\nUsamos o dataset de câncer de mama (`sklearn.datasets`), balanceado moderadamente. Separação em treino/teste estratificada para avaliar generalização."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "data = load_breast_cancer()\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\nprint(f\"Treino: {X_train.shape}, Teste: {X_test.shape}\")\nprint(pd.Series(y_train).value_counts(normalize=True).rename('prop_train'))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Modelos comparados e validação cruzada\n\nAvaliamos 4 modelos com hiperparâmetros simples:\n- **Regressão Logística** (baseline linear, com padronização).\n- **SVM (RBF)** com `C=3`, `gamma='scale'` e probabilidade habilitada.\n- **Random Forest** com 200 árvores, profundidade máxima 6.\n- **Gradient Boosting** com 120 estimadores, `learning_rate=0.05`.\n\nUsamos validação cruzada estratificada (5 folds) no conjunto de treino para comparar acurácia e F1."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nmodelos = {\n    'Logistic': Pipeline([\n        ('scaler', StandardScaler()),\n        ('clf', LogisticRegression(max_iter=200))\n    ]),\n    'SVM_RBF': Pipeline([\n        ('scaler', StandardScaler()),\n        ('clf', SVC(kernel='rbf', C=3, gamma='scale', probability=True))\n    ]),\n    'RandomForest': RandomForestClassifier(n_estimators=200, max_depth=6, random_state=42),\n    'GradientBoosting': GradientBoostingClassifier(n_estimators=120, learning_rate=0.05, random_state=42)\n}\n\nresultados = []\nfor nome, modelo in modelos.items():\n    acc = cross_val_score(modelo, X_train, y_train, cv=cv, scoring='accuracy').mean()\n    f1 = cross_val_score(modelo, X_train, y_train, cv=cv, scoring='f1').mean()\n    resultados.append({'modelo': nome, 'acc_cv': acc, 'f1_cv': f1})\n\npd.DataFrame(resultados).sort_values('acc_cv', ascending=False)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Curvas ROC e PR para os dois melhores modelos\n\nTreinamos em todo o treino e avaliamos no teste, gerando métricas e curvas para comparar calibragem de probabilidade e separação entre classes."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def avaliar_modelo(nome, modelo):\n    modelo.fit(X_train, y_train)\n    probas = modelo.predict_proba(X_test)[:, 1]\n    preds = modelo.predict(X_test)\n    fpr, tpr, _ = roc_curve(y_test, probas)\n    prec, rec, _ = precision_recall_curve(y_test, probas)\n    return {\n        'nome': nome,\n        'report': classification_report(y_test, preds, output_dict=True),\n        'roc': (fpr, tpr, auc(fpr, tpr)),\n        'pr': (prec, rec, average_precision_score(y_test, probas))\n    }\n\nmelhores = ['GradientBoosting', 'SVM_RBF']\navaliacoes = {n: avaliar_modelo(n, modelos[n]) for n in melhores}\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\nfor nome, dados in avaliacoes.items():\n    fpr, tpr, roc_auc = dados['roc']\n    axes[0].plot(fpr, tpr, label=f\"{nome} (AUC={roc_auc:.3f})\")\naxes[0].plot([0,1],[0,1], 'k--')\naxes[0].set_xlabel('FPR')\naxes[0].set_ylabel('TPR')\naxes[0].set_title('Curva ROC (teste)')\naxes[0].legend()\n\nfor nome, dados in avaliacoes.items():\n    prec, rec, ap = dados['pr']\n    axes[1].plot(rec, prec, label=f\"{nome} (AP={ap:.3f})\")\naxes[1].set_xlabel('Recall')\naxes[1].set_ylabel('Precisão')\naxes[1].set_title('Curva Precisão-Recall (teste)')\naxes[1].legend()\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Relatório agregado das métricas de teste\nlinhas = []\nfor nome, dados in avaliacoes.items():\n    report = dados['report']\n    linhas.append({\n        'modelo': nome,\n        'precision': report['weighted avg']['precision'],\n        'recall': report['weighted avg']['recall'],\n        'f1': report['weighted avg']['f1-score'],\n        'roc_auc': dados['roc'][2],\n        'ap': dados['pr'][2]\n    })\n\npd.DataFrame(linhas).sort_values('f1', ascending=False)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Hiperparâmetros testados (resumo)\n\n| Modelo | Principais hiperparâmetros |\n| --- | --- |\n| Logistic | `C=1.0`, `penalty='l2'`, `max_iter=200`, com `StandardScaler` |\n| SVM_RBF | `C=3`, `gamma='scale'`, `probability=True`, com `StandardScaler` |\n| RandomForest | `n_estimators=200`, `max_depth=6`, `min_samples_leaf=2`, `random_state=42` |\n| GradientBoosting | `n_estimators=120`, `learning_rate=0.05`, `max_depth=3 (padrão)`, `random_state=42` |\n\nOs ensembles (Random Forest e Gradient Boosting) aumentam custo computacional, mas o Gradient Boosting apresentou melhor AUC/F1 nos testes preliminares."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}