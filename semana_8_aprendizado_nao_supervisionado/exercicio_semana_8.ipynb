{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Semana 8 — Aprendizado Não Supervisionado\n\nEste notebook explora clustering (K-means e DBSCAN), redução de dimensionalidade com PCA e um autoencoder simples para reconstrução de dados."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_moons, load_digits\nfrom sklearn.cluster import KMeans, DBSCAN\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nplt.style.use('seaborn-v0_8')\nnp.random.seed(42)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Dados 2D para clustering\n\nUsamos `make_moons` para gerar dois grupos não-lineares com ruído."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "X, _ = make_moons(n_samples=500, noise=0.08, random_state=42)\n\nfig, ax = plt.subplots(figsize=(5, 4))\nax.scatter(X[:, 0], X[:, 1], s=20, alpha=0.6)\nax.set_title('Dados 2D (make_moons)')\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## K-means vs. DBSCAN\n\nComparamos K-means (assume clusters esféricos) com DBSCAN (baseado em densidade)."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "kmeans = KMeans(n_clusters=2, random_state=42)\nlabels_km = kmeans.fit_predict(X)\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# DBSCAN costuma precisar de dados escalados\nlabels_db = DBSCAN(eps=0.35, min_samples=8).fit_predict(X_scaled)\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\naxes[0].scatter(X[:, 0], X[:, 1], c=labels_km, cmap='viridis', s=20)\naxes[0].set_title('K-means (k=2)')\n\naxes[1].scatter(X[:, 0], X[:, 1], c=labels_db, cmap='viridis', s=20)\naxes[1].set_title('DBSCAN')\nplt.show()\n\n# Métricas de silhueta (quando há mais de um cluster)\nif len(set(labels_km)) > 1:\n    print('Silhueta K-means:', silhouette_score(X, labels_km))\nif len(set(labels_db)) > 1 and -1 not in set(labels_db):\n    print('Silhueta DBSCAN:', silhouette_score(X, labels_db))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## PCA em dados de alta dimensionalidade (Digits)\n\nAplicamos PCA para reduzir 64 dimensões para 2 e visualizar a separação dos dígitos."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "digits = load_digits()\nX_digits = digits.data\n\npca = PCA(n_components=2, random_state=42)\nX_2d = pca.fit_transform(X_digits)\n\nfig, ax = plt.subplots(figsize=(6, 5))\nscatter = ax.scatter(X_2d[:, 0], X_2d[:, 1], c=digits.target, cmap='tab10', s=15)\nax.set_title('PCA (2D) nos dígitos')\nax.set_xlabel('PC1')\nax.set_ylabel('PC2')\nlegend = ax.legend(*scatter.legend_elements(num=10), title='Dígitos', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## K-means com e sem PCA (exercício guiado)\n\nAplicamos K-means diretamente nos dados e depois em uma versão reduzida por PCA (30 componentes) para comparar silhueta e tempo de treinamento."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import time\n\nkmeans_raw = KMeans(n_clusters=10, random_state=42)\nstart = time.time()\nlabels_raw = kmeans_raw.fit_predict(X_digits)\nraw_time = time.time() - start\n\npca_30 = PCA(n_components=30, random_state=42)\nX_pca30 = pca_30.fit_transform(X_digits)\n\nkmeans_pca = KMeans(n_clusters=10, random_state=42)\nstart = time.time()\nlabels_pca = kmeans_pca.fit_predict(X_pca30)\npca_time = time.time() - start\n\nsil_raw = silhouette_score(X_digits, labels_raw)\nsil_pca = silhouette_score(X_pca30, labels_pca)\n\npd.DataFrame([\n    {'metodo': 'K-means raw', 'silhueta': sil_raw, 'tempo_s': raw_time},\n    {'metodo': 'K-means + PCA(30)', 'silhueta': sil_pca, 'tempo_s': pca_time}\n])\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Autoencoder simples (Keras)\n\nImplementamos um autoencoder denso para reconstruir os dígitos. O objetivo é reduzir dimensionalidade aprendendo uma representação comprimida.\n\n> **Observação:** Execute esta célula apenas se `tensorflow/keras` estiver disponível no ambiente."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Normalização dos dígitos\nX_auto = X_digits / 16.0\n\ninput_dim = X_auto.shape[1]\nencoding_dim = 16\n\ninput_layer = keras.Input(shape=(input_dim,))\nencoded = layers.Dense(32, activation='relu')(input_layer)\nencoded = layers.Dense(encoding_dim, activation='relu')(encoded)\ndecoded = layers.Dense(32, activation='relu')(encoded)\ndecoded = layers.Dense(input_dim, activation='sigmoid')(decoded)\n\nautoencoder = keras.Model(input_layer, decoded)\nautoencoder.compile(optimizer='adam', loss='mse')\n\nhistory = autoencoder.fit(\n    X_auto, X_auto,\n    epochs=30,\n    batch_size=64,\n    validation_split=0.2,\n    verbose=0\n)\n\nrecon = autoencoder.predict(X_auto[:10])\nrecon_error = np.mean((X_auto[:10] - recon) ** 2)\nprint(f\"Erro médio de reconstrução (10 amostras): {recon_error:.4f}\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Resumo\n\n- K-means funciona bem em clusters convexos, mas falha em formas não lineares; DBSCAN captura densidade e detecta ruído.\n- PCA ajuda a reduzir custo computacional e pode melhorar separação em clusters quando remove ruído.\n- Autoencoders fornecem uma representação compacta para reconstrução de dados, útil para redução de dimensionalidade não linear."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}