# Semana 10 – Redes Neurais e Deep Learning

**Cronograma:** 06/10/2025 (início) a 09/11/2025 (entrega - domingo)

## Objetivos de aprendizagem
- Construir modelos MLP, CNN e RNN básicos.
- Aplicar técnicas de regularização e melhoria de treinamento.
- Entender casos de uso de CNN para visão e RNN/LSTM para sequências.

## Tópicos-chave
- Redes Neurais Artificiais (MLP) e funções de ativação.
- Redes Convolucionais (CNN) para visão computacional.
- Redes Recorrentes (RNN, LSTM) para dados sequenciais.
- Treinamento, normalização, dropout e early stopping.

## Entregas
- Notebook com um MLP simples em `keras` ou `pytorch` aplicado a um problema tabular.
- Implementação de uma CNN para classificação de imagens (ex.: CIFAR-10 ou Fashion-MNIST) com métricas de validação.
- Protótipo de RNN ou LSTM em um dataset textual curto para prever a próxima palavra/caractere.

## Leituras sugeridas
- "Deep Learning" – Goodfellow, Bengio & Courville (capítulos 6–10).
- Documentação `keras` ou `pytorch` sobre camadas convolucionais e recorrentes.

## Exercício guiado
- Compare performance de uma CNN raso com e sem técnicas de regularização (dropout, data augmentation). Relate impacto na acurácia de validação e no tempo de treinamento.
