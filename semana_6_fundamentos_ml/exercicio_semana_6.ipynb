{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Semana 6 — Fundamentos de Aprendizado de Máquina\n\nEste notebook cobre um exercício guiado para visualizar underfitting e overfitting em um problema de regressão, avaliar regularização L2 e registrar boas práticas de preparo e avaliação de modelos."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, learning_curve\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.metrics import mean_squared_error\n\nplt.style.use('seaborn-v0_8')\nnp.random.seed(42)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Geração de dados sintéticos\n\nUsamos um polinômio cúbico com ruído para ter uma relação não linear moderada. Dividimos em treino/validação/teste para avaliar generalização."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def gerar_dados(n=160, ruido=3.5):\n    X = np.random.uniform(-3, 3, size=n)\n    y = 0.5 * X**3 - X**2 + 2 * X + np.random.normal(scale=ruido, size=n)\n    return X.reshape(-1, 1), y\n\nX, y = gerar_dados()\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\nprint(f\"Tamanhos: treino={len(X_train)}, validacao={len(X_val)}, teste={len(X_test)}\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "fig, ax = plt.subplots(figsize=(6, 4))\nax.scatter(X_train, y_train, alpha=0.6, label='treino')\nax.scatter(X_val, y_val, alpha=0.6, label='validacao')\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.legend()\nax.set_title('Dados com ruido')\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Modelos com diferentes complexidades\n\nAvaliaremos regressão linear com graus polinomiais 1, 3 e 8.\n- Grau 1: provável underfitting.\n- Grau 3: próximo da função geradora.\n- Grau 8: alta flexibilidade, sujeito a overfitting."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def treinar_avaliar(degree):\n    modelo = Pipeline([\n        ('poly', PolynomialFeatures(degree=degree, include_bias=False)),\n        ('reg', LinearRegression())\n    ])\n    modelo.fit(X_train, y_train)\n    def rmse(X_set, y_set):\n        preds = modelo.predict(X_set)\n        return mean_squared_error(y_set, preds, squared=False)\n    return {\n        'grau': degree,\n        'rmse_treino': rmse(X_train, y_train),\n        'rmse_valid': rmse(X_val, y_val),\n        'rmse_teste': rmse(X_test, y_test)\n    }, modelo\n\navaliacoes = []\nmodelos = {}\nfor grau in [1, 3, 8]:\n    res, model = treinar_avaliar(grau)\n    avaliacoes.append(res)\n    modelos[grau] = model\n\npd.DataFrame(avaliacoes)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "grid = np.linspace(-3.5, 3.5, 200).reshape(-1, 1)\nfig, axes = plt.subplots(1, 3, figsize=(15, 4), sharey=True)\nfor ax, grau in zip(axes, [1, 3, 8]):\n    ax.scatter(X_train, y_train, color='gray', alpha=0.4, label='treino')\n    ax.scatter(X_val, y_val, color='tab:orange', alpha=0.5, label='validacao')\n    preds = modelos[grau].predict(grid)\n    ax.plot(grid, preds, color='tab:blue')\n    ax.set_title(f'Grau {grau}')\n    ax.set_xlabel('x')\naxes[0].set_ylabel('y')\naxes[0].legend()\nfig.suptitle('Curvas ajustadas vs. dados')\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Curvas de aprendizado\n\nComparamos um modelo simples (grau 2) e um modelo complexo (grau 8) à medida que o tamanho de treino cresce. Overfitting aparece quando o erro de treino é baixo, mas o de validação permanece alto."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def plot_learning_curve(degree, ax):\n    modelo = Pipeline([\n        ('poly', PolynomialFeatures(degree=degree, include_bias=False)),\n        ('reg', LinearRegression())\n    ])\n    train_sizes, train_scores, val_scores = learning_curve(\n        modelo, X_train, y_train, cv=5, train_sizes=np.linspace(0.1, 1.0, 8), scoring='neg_root_mean_squared_error'\n    )\n    train_rmse = -train_scores.mean(axis=1)\n    val_rmse = -val_scores.mean(axis=1)\n    ax.plot(train_sizes, train_rmse, label='treino')\n    ax.plot(train_sizes, val_rmse, label='validacao')\n    ax.set_title(f'Curva de aprendizado (grau {degree})')\n    ax.set_xlabel('amostras de treino')\n    ax.set_ylabel('RMSE')\n    ax.legend()\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\nplot_learning_curve(2, axes[0])\nplot_learning_curve(8, axes[1])\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Regularização L2 (Ridge)\n\nAplicamos Ridge com grau 8 para suavizar coeficientes e reduzir overfitting. Comparamos com o modelo não regularizado."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def avaliar_ridge(alpha):\n    modelo = Pipeline([\n        ('poly', PolynomialFeatures(degree=8, include_bias=False)),\n        ('reg', Ridge(alpha=alpha))\n    ])\n    modelo.fit(X_train, y_train)\n    def rmse(X_set, y_set):\n        return mean_squared_error(y_set, modelo.predict(X_set), squared=False)\n    return {\n        'alpha': alpha,\n        'rmse_treino': rmse(X_train, y_train),\n        'rmse_valid': rmse(X_val, y_val),\n        'rmse_teste': rmse(X_test, y_test)\n    }, modelo\n\nridge_result, ridge_model = avaliar_ridge(alpha=5.0)\nlin_result, lin_model = treinar_avaliar(8)\npd.DataFrame([lin_result | {'modelo': 'Linear'}, ridge_result | {'modelo': 'Ridge'}])[['modelo','alpha','rmse_treino','rmse_valid','rmse_teste']]\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "fig, ax = plt.subplots(figsize=(6, 4))\nax.scatter(X_train, y_train, color='gray', alpha=0.4, label='treino')\nax.scatter(X_val, y_val, color='tab:orange', alpha=0.5, label='validacao')\npred_lin = lin_model.predict(grid)\npred_ridge = ridge_model.predict(grid)\nax.plot(grid, pred_lin, color='tab:red', label='Grau 8 sem reg.')\nax.plot(grid, pred_ridge, color='tab:green', label='Grau 8 Ridge')\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.legend()\nax.set_title('Efeito da regularizacao L2')\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Boas práticas registradas\n\n- Separar dados em treino/validação/teste para medir generalização.\n- Usar validação cruzada quando o conjunto é pequeno para reduzir variância das métricas.\n- Monitorar curvas de aprendizado para diagnosticar under/overfitting.\n- Incluir regularização (ex.: L2) ou reduzir complexidade quando o erro de validação é muito maior que o de treino.\n- Normalizar/escala de atributos para algoritmos sensíveis à magnitude e para regularização atuar de forma equilibrada.\n- Fixar semente aleatória para reprodutibilidade e registrar métricas de teste apenas após finalizar tuning."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}