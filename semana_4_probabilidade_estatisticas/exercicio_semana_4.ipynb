{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercícios – Semana 4: Probabilidade e Estatística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook contém soluções para os exercícios da semana 4, cobrindo distribuição de probabilidades, inferência bayesiana e testes estatísticos. Cada seção pode ser executada de forma independente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Probabilidades básicas e transformações de distribuições\n\nA célula seguinte calcula probabilidades em distribuições Bernoulli e Binomial e mostra como aplicar transformações simples (normalização) em variáveis aleatórias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade de sucesso em 3 lançamentos de moeda viciada\n",
    "p_sucesso = 0.6\n",
    "n_lancamentos = 3\n",
    "# Probabilidade de obter exatamente 2 caras\n",
    "p_2_caras = stats.binom.pmf(2, n_lancamentos, p_sucesso)\n",
    "# Probabilidade acumulada de obter até 1 cara\n",
    "p_ate_1_cara = stats.binom.cdf(1, n_lancamentos, p_sucesso)\n",
    "\n",
    "# Transformação: centralização e normalização de uma variável aleatória simulada\n",
    "samples = stats.bernoulli.rvs(p_sucesso, size=1_000)\n",
    "normalized_samples = (samples - samples.mean()) / samples.std()\n",
    "\n",
    "p_2_caras, p_ate_1_cara, float(normalized_samples.mean()), float(normalized_samples.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classificador Naïve Bayes (GaussianNB)\n\nGeramos dados sintéticos com duas classes, treinamos um classificador Naïve Bayes Gaussiano e avaliamos a acurácia. Os resultados devem ficar em torno de 85–95%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=6, n_informative=4, n_redundant=0, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelo de mistura Gaussiana (GMM)\n\nA célula a seguir ajusta um GMM a dados bidimensionais e calcula a pontuação de verossimilhança média por amostra. Essa abordagem pode ser usada para clusterização não supervisionada ou detecção de anomalias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_blobs, _ = make_blobs(n_samples=400, centers=3, cluster_std=0.8, random_state=42)\n",
    "\n",
    "gmm = GaussianMixture(n_components=3, covariance_type=\"full\", random_state=42)\n",
    "gmm.fit(X_blobs)\n",
    "average_log_likelihood = gmm.score(X_blobs)\n",
    "gmm.means_.round(2), round(average_log_likelihood, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulação de teste A/B\n\nFunção utilitária para simular um teste A/B com duas variantes, calculando p-valor do teste z para proporções, intervalo de confiança para a diferença de conversão e uma decisão simples baseada em nível de significância.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_ab_test(n_a: int, n_b: int, p_a: float, p_b: float, alpha: float = 0.05):\n",
    "    \"\"\"Simula contagens de conversão, calcula p-valor (teste z) e intervalo de confiança.\n",
    "\n",
    "    Retorna um dicionário com resumo das métricas.\"\"\"\n",
    "    # Simular conversões em Bernoulli\n",
    "    conv_a = np.random.binomial(n_a, p_a)\n",
    "    conv_b = np.random.binomial(n_b, p_b)\n",
    "\n",
    "    # Taxas observadas\n",
    "    rate_a = conv_a / n_a\n",
    "    rate_b = conv_b / n_b\n",
    "    diff = rate_b - rate_a\n",
    "\n",
    "    # Estatística z para diferença de proporções\n",
    "    p_pool = (conv_a + conv_b) / (n_a + n_b)\n",
    "    se = math.sqrt(p_pool * (1 - p_pool) * (1 / n_a + 1 / n_b))\n",
    "    z_score = diff / se if se > 0 else 0.0\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "\n",
    "    # Intervalo de confiança para a diferença\n",
    "    z_alpha = stats.norm.ppf(1 - alpha / 2)\n",
    "    ci_low = diff - z_alpha * se\n",
    "    ci_high = diff + z_alpha * se\n",
    "\n",
    "    decision = \"Rejeita H0 (há evidência de diferença)\" if p_value < alpha else \"Falha em rejeitar H0\"\n",
    "\n",
    "    return {\n",
    "        \"conversoes\": {\"A\": int(conv_a), \"B\": int(conv_b)},\n",
    "        \"taxas\": {\"A\": round(rate_a, 4), \"B\": round(rate_b, 4)},\n",
    "        \"diferenca\": round(diff, 4),\n",
    "        \"p_valor\": round(p_value, 4),\n",
    "        \"intervalo_confianca\": (round(ci_low, 4), round(ci_high, 4)),\n",
    "        \"decisao\": decision\n",
    "    }\n",
    "\n",
    "# Exemplo de uso: cenário com melhoria de 1 ponto percentual\n",
    "resultado_ab = simulate_ab_test(n_a=5000, n_b=5000, p_a=0.1, p_b=0.11)\n",
    "resultado_ab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observações\n- Ajuste os parâmetros de `simulate_ab_test` para analisar diferentes tamanhos de amostra e efeitos mínimos detectáveis.\n- Ao interpretar p-valores, considere também a potência do teste e os custos de falso positivo/falso negativo.\n- O intervalo de confiança oferece uma noção de magnitude da diferença, não apenas significância.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolução resumida\n",
    "- **Binomial:** P(X=2)=C(3,2)·0,6^2·0,4=0,432 e P(X≤1)=0,4^3+3·0,6·0,4^2=0,352. A normalização centraliza a média em ~0 e o desvio padrão em ~1.\n",
    "- **Naïve Bayes:** o classificador é treinado e avaliado no conjunto de teste, retornando uma acurácia típica entre 0,85–0,95 para o cenário sintético.\n",
    "- **GMM:** o ajuste recupera três centróides próximos aos centros dos blobs e reporta uma log-verossimilhança média por amostra para avaliar o ajuste.\n",
    "- **Teste A/B:** o z-teste compara as taxas; p-valor < α implica rejeitar H0 e o IC informa a magnitude do efeito.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}